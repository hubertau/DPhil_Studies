
# 2021-07-12 Problems with python implementation
* in order to get a decent graphviz we want a graph object. Right? But the R implementation obviously doesn't allow for that.
* But it might - there are matrices involved in there for sure, and how can we visualise these?
* uhtMat is the last matrix object that is then kmeans clustered. I can change what the outputs of these are.
* Idea 2021-07-13: take matrix out of function and then visualise using that matrix.
* Q: how is it that there are only 832 items/phrases?
* THE FUCKING GRAPH ADJACENCY MATRIX THEY HAD DID NOT TRANSFER EDGE WEIGHT
* python: getting a NaN warning from sklearn. Does input need to be dense?
	* nope.
	* perhaps need to drop rows that are 0?
	* adding small diagonal can help better condition the matrix https://stackoverflow.com/questions/18754324/improving-a-badly-conditioned-matrix

* see this for bipartite viz: https://stackoverflow.com/questions/60100006/visualize-bipartite-network-graph-created-using-pandas-dataframe

* also, how to convert between unipartite and bipartite graph type in R:
	* just add a $type attribute

* also,  

# 2021-06-30 Graph Visualisation
* The key problem here is that the graph, when partititioned, does not have multiple assignment. So there will be no overlap in users and phrases assigned across clusters, and a visualisation should have some kind of distance measure. What to do with this?
	* Yesterday I found https://github.com/Nicola17/High-Dimensional-Inspector
	* Perhaps links between users and phrases across clusters, those will still exist
	* but still need to make appropriate adjacency matrix after clustering. How to do?
	* the clustering _is_ a form of rearranging rows of an adjacency matrix. So perhaps don't use the R implementation? Found a python one, but was written in Python 2. need to check if still working.
	* from [@steinbockCasualVisualExploration2018], Common strategies to visualize large graphs – and large data sets in general – are ﬁltering (i.e., removing items) and aggregation (i.e., grouping items)
	* https://scikit-learn.org/stable/modules/biclustering.html biclustering is implemented in sklearn!!!


# 2021-06-21 meeting with Balazs

* FAS collection used this month - 10m for 6 months of tweets.
* BSC results up and running, I can send you the files
* Things suggested to work on:
	* I now have a couple months of FAS on a fuller set of collection data
	* I can start more systematically looking through accounts with clustering information to (a) control for word use to decode who is an activist or not
		* (b) prepare sampling of users for July collection.
---
* use individal plots of course
* strength of dyad
	* follow collaborator
	* normalise histories where a bot was introduced and where a bot was not introduced.
	* counterfactual comparison
	* marginals like account same age, collaboration intensity, normalise out seasonality dynamics, approximate true effect of introduction of bot.
	* seasonality probably not relevant here.

* we do expect an increase across metoo but activist should but compared to what?
* DO VISUALISATION on SPACE for sense of regions
	* correspondence analysis
	* pca, non metric muiltidimensional scaling MDS, correspondnece (bipartite)
	* e.g. measure distance from one cluster to another cluster
	* same measure generating clusters can be used to get distance

* baselines comparisons IMPORTANT!
	* need COUNTERFACTUALS

* distance metric between clusters!
* hashtag pool use
* hashtag cofrequency
* aggregate cofrequency link between clusters