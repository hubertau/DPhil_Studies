source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
pwd()
getwd()
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/util.R')
library(bit64)
library(data.table)
library(igraph)
library(Matrix)
library(rARPACK)
library(wordcloud)
library(ggplot2)
library(dplyr)
library(irlba)
library(stringr)
###
# This is based on the original bi-spectral clustering script, modified to take cammand line arguments
###
library(argparser, quietly=TRUE)
# Create a parser
parser <- arg_parser("Round a floating point number")
parser <- add_argument(parser,
"filename",
help="The user to hashtag edgelist filename that is required for the clustering"
)
parser <- add_argument(parser,
"outdir",
help="The output directory"
)
# parse argument
args <- parse_args(parser,
c("collection_results_2021_05_04_16_22/bispec_ready_counts.csv",
"collection_results_2021_05_04_16_22/bsc/")
)
# date
report_date <- Sys.Date()
# Where is your user to hashtag matrix? Make sure it is as defined in the Readme!
USER_TO_HASHTAG_EDGELIST_FILENAME <- args$filename
OUTPUT_DIRECTORY <- args$outdir
# load r utils
source("util.R")
#Paramters for bispectral coclustering
## What is the minimum number of users a hashtag must have been used by to be included?
MIN_USER = 10
## How many clusters do we want?
N_CLUSTERS = 10
# You can optionally identify some users (we do this via ID) and hashtags that you are particularly interested in here
known_important_users <- c("29417304","755113","16948493")
known_important_hashtags <- c("charlotteprotests", "keithlamontscott",
"charlotte","charlotteriot","charlottepd",
"charlotteuprising","blacklivesmatter")
# load the data in
if(grep("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)){
# Note, you might not be able to use zcat here, esp. if on Windows. There are other ways to read in gzipped files though!
user_ht <- load_user_ht_matrix(paste0("zcat < ", USER_TO_HASHTAG_EDGELIST_FILENAME))
} else {
user_ht <- fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
}
grep("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)
fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
if(grep("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)){
# Note, you might not be able to use zcat here, esp. if on Windows. There are other ways to read in gzipped files though!
user_ht <- load_user_ht_matrix(paste0("zcat < ", USER_TO_HASHTAG_EDGELIST_FILENAME))
} else {
user_ht <- fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
}
# load the data in
if(grepl("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)){
# Note, you might not be able to use zcat here, esp. if on Windows. There are other ways to read in gzipped files though!
user_ht <- load_user_ht_matrix(paste0("zcat < ", USER_TO_HASHTAG_EDGELIST_FILENAME))
} else {
user_ht <- fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
}
# run bispectral clustering
## The function takes as input the
listObj=biSpectralCoCluster(user_ht,min_user=MIN_USER,k=N_CLUSTERS)
View(user_ht)
## How many clusters do we want?
N_CLUSTERS = 15
# You can optionally identify some users (we do this via ID) and hashtags that you are particularly interested in here
known_important_users <- c("29417304","755113","16948493")
known_important_hashtags <- c("charlotteprotests", "keithlamontscott",
"charlotte","charlotteriot","charlottepd",
"charlotteuprising","blacklivesmatter")
# load the data in
if(grepl("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)){
# Note, you might not be able to use zcat here, esp. if on Windows. There are other ways to read in gzipped files though!
user_ht <- load_user_ht_matrix(paste0("zcat < ", USER_TO_HASHTAG_EDGELIST_FILENAME))
} else {
user_ht <- fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
}
# run bispectral clustering
## The function takes as input the
listObj=biSpectralCoCluster(user_ht,min_user=MIN_USER,k=N_CLUSTERS)
# load r utils
source("util.R")
#Paramters for bispectral coclustering
## What is the minimum number of users a hashtag must have been used by to be included?
MIN_USER = 10
## How many clusters do we want?
N_CLUSTERS = 15
# You can optionally identify some users (we do this via ID) and hashtags that you are particularly interested in here
known_important_users <- c("29417304","755113","16948493")
known_important_hashtags <- c("charlotteprotests", "keithlamontscott",
"charlotte","charlotteriot","charlottepd",
"charlotteuprising","blacklivesmatter")
# load the data in
if(grepl("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)){
# Note, you might not be able to use zcat here, esp. if on Windows. There are other ways to read in gzipped files though!
user_ht <- load_user_ht_matrix(paste0("zcat < ", USER_TO_HASHTAG_EDGELIST_FILENAME))
} else {
user_ht <- fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
}
# run bispectral clustering
## The function takes as input the
listObj=biSpectralCoCluster(user_ht,min_user=MIN_USER,k=N_CLUSTERS)
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
###
# This is based on the original bi-spectral clustering script, modified to take cammand line arguments
###
library(argparser, quietly=TRUE)
# Create a parser
parser <- arg_parser("Round a floating point number")
parser <- add_argument(parser,
"filename",
help="The user to hashtag edgelist filename that is required for the clustering"
)
parser <- add_argument(parser,
"outdir",
help="The output directory"
)
# parse argument
args <- parse_args(parser,
c("collection_results_2021_05_04_16_22/bispec_ready_counts.csv",
"collection_results_2021_05_04_16_22/bsc/")
)
# date
report_date <- Sys.Date()
# Where is your user to hashtag matrix? Make sure it is as defined in the Readme!
USER_TO_HASHTAG_EDGELIST_FILENAME <- args$filename
OUTPUT_DIRECTORY <- args$outdir
# load r utils
source("util.R")
#Paramters for bispectral coclustering
## What is the minimum number of users a hashtag must have been used by to be included?
MIN_USER = 10
## How many clusters do we want?
N_CLUSTERS = 15
# You can optionally identify some users (we do this via ID) and hashtags that you are particularly interested in here
known_important_users <- c("29417304","755113","16948493")
known_important_hashtags <- c("charlotteprotests", "keithlamontscott",
"charlotte","charlotteriot","charlottepd",
"charlotteuprising","blacklivesmatter")
# load the data in
if(grepl("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)){
# Note, you might not be able to use zcat here, esp. if on Windows. There are other ways to read in gzipped files though!
user_ht <- load_user_ht_matrix(paste0("zcat < ", USER_TO_HASHTAG_EDGELIST_FILENAME))
} else {
user_ht <- fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
}
# run bispectral clustering
## The function takes as input the
listObj=biSpectralCoCluster(user_ht,min_user=MIN_USER,k=N_CLUSTERS)
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
h_edges <- user_ht
H=graph.data.frame(h_edges)
S=simplify(H,remove.loops=FALSE,remove.multiple=TRUE)
rm(h_edges)
A=get.adjacency(H,names=TRUE)
S=get.adjacency(S)
mapping=grepl('#',V(H)$name)
A=A[,mapping]
S=S[,mapping]
rm(H)
A=A[!mapping,]
S=S[!mapping,]
ht_mapping= colSums(S)>=min_user
A=A[,ht_mapping]
rm(S)
A
View(A)
H=graph.data.frame(h_edges)
S=simplify(H,remove.loops=FALSE,remove.multiple=TRUE)
rm(h_edges)
A=get.adjacency(H,names=TRUE)
S=get.adjacency(S)
h_edges <- user_ht
H=graph.data.frame(h_edges)
S=simplify(H,remove.loops=FALSE,remove.multiple=TRUE)
A=get.adjacency(H,names=TRUE)
A
mapping=grepl('#',V(H)$name)
V(H)
V()
library(dplyr)
z <- user_ht %<%
z <- user_ht %>%
group_by(Target)
View(z)
z <- user_ht %<%
group_by(Target)
z <- user_ht %>%
group_by(Target) %>%
summarise(count = n())
View(z)
z <- user_ht %>%
group_by(Source) %>%
summarise(count = n())
View(user_ht)
type(V(H))
V(H)$names
V(H)$name
clear
grepl('[^0-9+\-]',V(H)$name)
grepl('[^0-9]*',V(H)$name)
grepl('[^0-9]',V(H)$name)
grepl('[^\d]',V(H)$name)
grepl("[^\d]",V(H)$name)
grepl("[^\\d]",V(H)$name)
grepl("^[0-9]+$",V(H)$name)
mapping=!grepl("^[0-9]+$", V(H)$name)
mapping=!grepl("^[0-9]+$", V(H)$name)
A=A[,mapping]
S=S[,mapping]
A=A[!mapping,]
S=S[!mapping,]
ht_mapping= colSums(S)>=min_user
A=A[,ht_mapping]
min_user=10
ht_mapping= colSums(S)>=min_user
A=A[,ht_mapping]
rm(S)
k=15
start = Sys.time()
Ucount=rowSums(A)
HTcount=colSums(A)
d1=1/sqrt(rowSums(A))
d1[is.infinite(d1)]=0
D1=Diagonal(n=dim(A)[1],x=d1)
d2=1/sqrt(colSums(A))
d2[is.infinite(d2)]=0
D2=Diagonal(n=dim(A)[2],x=d2)
An=D1%*%A%*%D2
print(min(nrow(A), ncol(A)))
obj=irlba(An,k,nu=k,nv=k)
print(paste("Bispectral took:", Sys.time()-start,"seconds"))
uMat=data.frame(ID=rownames(A),degree=Ucount,as.matrix(D1%*%obj$u),stringsAsFactors=FALSE)
htMat=data.frame(ID=colnames(A),degree=HTcount,as.matrix(D2%*%obj$v),stringsAsFactors=FALSE)
uhtMat=rBind(uMat[,c(-1,-2)],htMat[,c(-1,-2)])
row.names(uhtMat)=c(uMat$ID,htMat$ID)
cat('spectral features extracted... clustering')
ht_kobj=kmeans(uhtMat,k,iter.max=10000,algorithm='Lloyd')
uMat=data.frame(uMat[,1:2],topic_cluster=ht_kobj$cluster[1:dim(uMat)[1]])
htMat=data.frame(htMat[,1:2],topic_cluster=ht_kobj$cluster[(dim(uMat)[1]+1):length(ht_kobj$cluster)])
names(htMat)[1]='hashtag'
summ=as.data.frame(ftable(uMat$topic_cluster))
names(summ)=c('cluster','count')
summ=summ[order(summ$count,decreasing=TRUE),]
return(list(summary=summ,users=uMat,hashtags=htMat))
###
# This is based on the original bi-spectral clustering script, modified to take cammand line arguments
###
library(argparser, quietly=TRUE)
# Create a parser
parser <- arg_parser("Round a floating point number")
parser <- add_argument(parser,
"filename",
help="The user to hashtag edgelist filename that is required for the clustering"
)
parser <- add_argument(parser,
"outdir",
help="The output directory"
)
# parse argument
args <- parse_args(parser,
c("collection_results_2021_05_04_16_22/bispec_ready_counts.csv",
"collection_results_2021_05_04_16_22/bsc/")
)
# date
report_date <- Sys.Date()
# Where is your user to hashtag matrix? Make sure it is as defined in the Readme!
USER_TO_HASHTAG_EDGELIST_FILENAME <- args$filename
OUTPUT_DIRECTORY <- args$outdir
# Where to place the output
# dir.create(OUTPUT_DIRECTORY)
# load r utils
source("util.R")
#Paramters for bispectral coclustering
## What is the minimum number of users a hashtag must have been used by to be included?
MIN_USER = 10
## How many clusters do we want?
N_CLUSTERS = 15
# You can optionally identify some users (we do this via ID) and hashtags that you are particularly interested in here
known_important_users <- c("29417304","755113","16948493")
known_important_hashtags <- c("charlotteprotests", "keithlamontscott",
"charlotte","charlotteriot","charlottepd",
"charlotteuprising","blacklivesmatter")
# load the data in
if(grepl("[.]gz$", USER_TO_HASHTAG_EDGELIST_FILENAME)){
# Note, you might not be able to use zcat here, esp. if on Windows. There are other ways to read in gzipped files though!
user_ht <- load_user_ht_matrix(paste0("zcat < ", USER_TO_HASHTAG_EDGELIST_FILENAME))
} else {
user_ht <- fread(USER_TO_HASHTAG_EDGELIST_FILENAME)
}
# run bispectral clustering
## The function takes as input the
listObj=biSpectralCoCluster(user_ht,min_user=MIN_USER,k=N_CLUSTERS)
# look at results
gen_plots(listObj,min_user_count = 1,filename=file.path(OUTPUT_DIRECTORY, "hashtags_per_cluster.pdf"))
warnings()
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
library(argparser, quietly=TRUE)
library(tidyverse)
getCurrentFileLocation <-  function()
{
this_file <- commandArgs() %>%
tibble::enframe(name = NULL) %>%
tidyr::separate(col=value, into=c("key", "value"), sep="=", fill='right') %>%
dplyr::filter(key == "--file") %>%
dplyr::pull(value)
if (length(this_file)==0)
{
this_file <- rstudioapi::getSourceEditorContext()$path
}
return(dirname(this_file))
}
getCurrentFileLocation()
install.packages('funr')
library(aricode)
listObj$user$topic_cluster
listObj$hashtags$topic_cluster
data(iris)
cl <- cutree(hclust(dist(iris[,-5])), 4)
cl
iris$Species
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/bispectral_clustering.R')
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
ht_kobj$centers
uhtMat[,1:2]
View(uhtMat)
2363+832
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
V(H)
V(H)$name
MIN_USER
MIN_USER
min_user
ht_mapping
sum(ht_mapping)
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
force(k)
colSums(S)
H$edges
S
max(S)
E(H)
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
typeof(H)
H
H$weight
x = get.adjacency(H, attr='weight')
x
max(x)
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
sum(ht_mapping)
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
# parse argument
args <- parse_args(parser,
c(
"/Users/hubert/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/collection_results_2021_05_04_16_22/bispec_ready_counts.csv",
"/Users/hubert/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/collection_results_2021_05_04_16_22/bsc/",
"--min_user", 10,
"--ncluster", 50
)
)
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
source('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
det(An)
dim(An)
determinant(An)
An
kappa(An)
An*45484
An+matrix(0, ncol=2, nrow=2)
An+matrix(0:0, ncol=2, nrow=2)
An+matrix(, ncol=2, nrow=2)
An+matrix(0, ncol=2, nrow=2)
An+matrix(0, ncol=2, nrow=3)
zzz <- matrix(0, ncol=2363, nrow=3363)
diag(zzz) <- 1
zzz
zzz[0]
zzz[1,1]
zzz[1,2]
zzz[5,5]
An+zzz
dim(zzz)
zzz <- matrix(0, ncol=3383, nrow=2363)
diag(zzz) <- 1
An+zzz
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000)
kappa(An+zzz)
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
An
zzz <- matrix(0, ncol=3383,nrow=2363)
diag(zzz) <- 1
diag(zzz) <- 0.01
zzz
zzz[1,1]
zzz[1,2]
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000)
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000, tol=1e-4, verbose=TRUE)
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
zzz <- matrix(0, ncol=3383,nrow=2363)
diag(zzz) <- 0.01
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000, tol=1e-4, verbose=TRUE)
kappa(An+zzz)
diag(zzz) <-0.1
kappa(An+zzz)
diag(zzz) <-0.5
kappa(An+zzz)
diag(zzz) <- 0.8
kappa(An+zzz)
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000, tol=1e-4, verbose=TRUE)
set.seed(0)
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000, tol=1e-4, verbose=TRUE, work=1000)
k=1000
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000, tol=1e-4, verbose=TRUE, work=1000)
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000, tol=1e-4, verbose=TRUE, work=2000)
for(l in 0.01:1){ cat(l )}
for(l in 0.01:1){ cat(l) }
for(k in 10:500){
for (l in 1:100){
l <- l/100
zzz <- matrix(0, ncol=3383, nrow=2363)
diag(zzz) <- l
obj=irlba(An+zzz,k,nu=k,nv=k,maxit = 2000, tol=1e-4, verbose=TRUE, work=2000)
}
}
for (l in 1:100 ){ cat(l)}
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
print(k,l)
print(k)
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
l
debugSource('~/Nextcloud/DPhil/DPhil_Studies/2021-04_Study_A_Diffusion/test_script_graph_obj.R')
V(H)$type
g <- sample_bipartite(10, 5, p=.4)
V(g)$type
V(H)$name
mapping=!grepl("^[0-9]+$", V(H)$name)
mapping
V(H)$type <- mapping
V(H)$type
H
plot(H)
V(H)$x
l <- layout.bipartite(H)
l
View(l)
plot(H, layout = l[, c(2,1)])
plot(H, layout = layout_as_bipartite, vertex.color=c("green","cyan")[V(g)$type+1])
plot(H)
