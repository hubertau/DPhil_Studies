{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021-10-26 Timeline stats\n",
    "\n",
    "Beginnings of statistical analysis based on the timeline stats of users, NOT the clustering word data yet. Also should I get the follows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tqdm\n",
    "import json\n",
    "import glob\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from collections import Counter\n",
    "sys.path.insert(0, '../src/d07_visualisation/')\n",
    "import datetime\n",
    "import h5py\n",
    "from typing import NamedTuple\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in search hashtags\n",
    "with open('../references/search_hashtags.txt', 'r') as f:\n",
    "    search_hashtags = f.readlines()\n",
    "    search_hashtags = [i.replace('\\n', '') for i in search_hashtags]\n",
    "    search_hashtags = [i.replace('#', '') for i in search_hashtags]\n",
    "    search_hashtags = [i.lower() for i in search_hashtags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_num = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data and basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_hdf5_file = '/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/03_processed/interactions.hdf5'\n",
    "\n",
    "# print(h5py.File(interactions_hdf5_file, 'r').keys())\n",
    "\n",
    "df = pd.read_hdf(interactions_hdf5_file,'interactions_group_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_in_reply_to(x):\n",
    "    if x:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['in_reply_to'] = df['in_reply_to'].apply(convert_in_reply_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove self replies\n",
    "\n",
    "df = df[df['author_id']!=df['in_reply_to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate counts of internal mentions/quotes/replies\n",
    "\n",
    "df['internal'] = df['in_reply_to'].isin(df['author_id'])\n",
    "# df['internal_mentions'] = df['mentions'].apply(lambda x: any(df['author_id'].isin(x)))\n",
    "\n",
    "# df['internal_replies'] = df['replies'].apply(lambda x: any(df['tweet_id'].isin(x)))\n",
    "# df['internal_quotes'] = df['quotes'].apply(lambda x: any(df['tweet_id'].isin(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal replies (not self replies): 275164\n",
      "Total df length: 7939920\n"
     ]
    }
   ],
   "source": [
    "internal = df['internal'].sum()\n",
    "print(f'Internal replies (not self replies): {internal}')\n",
    "print(f'Total df length: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1883.282732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2837.788446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>148.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>763.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2498.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26390.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id\n",
       "count   4216.000000\n",
       "mean    1883.282732\n",
       "std     2837.788446\n",
       "min        1.000000\n",
       "25%      148.750000\n",
       "50%      763.000000\n",
       "75%     2498.250000\n",
       "max    26390.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_interaction_counts = df[['author_id','tweet_id']].groupby('author_id').count()\n",
    "\n",
    "user_interaction_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple participation in protest networks\n",
    "Another preprocessing/data description step: How many how many users participate in more than one protest network in this time period **in their interactions**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       multiple_participation\n",
      "count             4216.000000\n",
      "mean                 3.486243\n",
      "std                 21.048806\n",
      "min                  0.000000\n",
      "25%                  0.000000\n",
      "50%                  0.000000\n",
      "75%                  1.000000\n",
      "max                855.000000\n",
      "multiple_participation    1302\n",
      "dtype: int64 users participate in more than one protest network in interactions\n"
     ]
    }
   ],
   "source": [
    "for hashtag in search_hashtags:\n",
    "    df['vocab:#'+hashtag] = df['contains_hashtags'].apply(lambda x: any(hashtag.lower() == item.lower() for item in x))\n",
    "\n",
    "#columns with vocab: in them\n",
    "vocab_colnames = [i for i in list(df.columns) if 'vocab:#' in i]\n",
    "\n",
    "df['network_participation'] = df[vocab_colnames].sum(axis=1)\n",
    "df['multiple_participation'] = df['network_participation']>1\n",
    "\n",
    "df_participate = df[['author_id','multiple_participation']].groupby('author_id').sum()\n",
    "\n",
    "print(df_participate.describe())\n",
    "\n",
    "above_one = (df_participate >= 1).sum()\n",
    "print(f'{above_one} users participate in more than one protest network in interactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to</th>\n",
       "      <th>mentions</th>\n",
       "      <th>quotes</th>\n",
       "      <th>replies</th>\n",
       "      <th>contains_hashtags</th>\n",
       "      <th>internal</th>\n",
       "      <th>vocab:#metoo</th>\n",
       "      <th>...</th>\n",
       "      <th>vocab:#noustoutes</th>\n",
       "      <th>vocab:#stilleforopptak</th>\n",
       "      <th>vocab:#nårdansenstopper</th>\n",
       "      <th>vocab:#nårmusikkenstilner</th>\n",
       "      <th>vocab:#memyös</th>\n",
       "      <th>vocab:#timesup</th>\n",
       "      <th>vocab:#niere</th>\n",
       "      <th>vocab:#jotambe</th>\n",
       "      <th>network_participation</th>\n",
       "      <th>multiple_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000884424190365697</td>\n",
       "      <td>1005675566</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>979806883472175105</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1000857122198966278]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000884337531916289</td>\n",
       "      <td>1005675566</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>25073877</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1000837182297464832]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000866554291130368</td>\n",
       "      <td>1005675566</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>2467791</td>\n",
       "      <td>[2467791]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1000862340450078720]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000767799898370048</td>\n",
       "      <td>1005675566</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>18277655</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1000371463705235456]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000668370457579520</td>\n",
       "      <td>1005675566</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>872909646</td>\n",
       "      <td>[16873455]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1000378615580774408]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581033</th>\n",
       "      <td>950212082313650176</td>\n",
       "      <td>99784623</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[950209985891446784]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[TIMESUP, TheFutureIsFemale]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581034</th>\n",
       "      <td>950205269983793155</td>\n",
       "      <td>99784623</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[950205133568307200]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[TIMESUP]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581035</th>\n",
       "      <td>999801367886692352</td>\n",
       "      <td>99784623</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>None</td>\n",
       "      <td>[17525171]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MeToo]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581036</th>\n",
       "      <td>998961892600229888</td>\n",
       "      <td>99784623</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>None</td>\n",
       "      <td>[24216951]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13ReasonsWhy, MeToo]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581037</th>\n",
       "      <td>998449372726743040</td>\n",
       "      <td>99784623</td>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>None</td>\n",
       "      <td>[15279429]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13ReasonsWhy, MeToo]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939920 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id   author_id  created_at         in_reply_to  \\\n",
       "0        1000884424190365697  1005675566  2018-05-27  979806883472175105   \n",
       "1        1000884337531916289  1005675566  2018-05-27            25073877   \n",
       "2        1000866554291130368  1005675566  2018-05-27             2467791   \n",
       "3        1000767799898370048  1005675566  2018-05-27            18277655   \n",
       "4        1000668370457579520  1005675566  2018-05-27           872909646   \n",
       "...                      ...         ...         ...                 ...   \n",
       "8581033   950212082313650176    99784623  2018-01-08                None   \n",
       "8581034   950205269983793155    99784623  2018-01-08                None   \n",
       "8581035   999801367886692352    99784623  2018-05-24                None   \n",
       "8581036   998961892600229888    99784623  2018-05-22                None   \n",
       "8581037   998449372726743040    99784623  2018-05-21                None   \n",
       "\n",
       "           mentions                quotes                replies  \\\n",
       "0                []                    []  [1000857122198966278]   \n",
       "1                []                    []  [1000837182297464832]   \n",
       "2         [2467791]                    []  [1000862340450078720]   \n",
       "3                []                    []  [1000371463705235456]   \n",
       "4        [16873455]                    []  [1000378615580774408]   \n",
       "...             ...                   ...                    ...   \n",
       "8581033          []  [950209985891446784]                     []   \n",
       "8581034          []  [950205133568307200]                     []   \n",
       "8581035  [17525171]                    []                     []   \n",
       "8581036  [24216951]                    []                     []   \n",
       "8581037  [15279429]                    []                     []   \n",
       "\n",
       "                    contains_hashtags  internal  vocab:#metoo  ...  \\\n",
       "0                                  []     False         False  ...   \n",
       "1                                  []     False         False  ...   \n",
       "2                                  []      True         False  ...   \n",
       "3                                  []     False         False  ...   \n",
       "4                                  []     False         False  ...   \n",
       "...                               ...       ...           ...  ...   \n",
       "8581033  [TIMESUP, TheFutureIsFemale]     False         False  ...   \n",
       "8581034                     [TIMESUP]     False         False  ...   \n",
       "8581035                       [MeToo]     False          True  ...   \n",
       "8581036         [13ReasonsWhy, MeToo]     False          True  ...   \n",
       "8581037         [13ReasonsWhy, MeToo]     False          True  ...   \n",
       "\n",
       "         vocab:#noustoutes  vocab:#stilleforopptak  vocab:#nårdansenstopper  \\\n",
       "0                    False                   False                    False   \n",
       "1                    False                   False                    False   \n",
       "2                    False                   False                    False   \n",
       "3                    False                   False                    False   \n",
       "4                    False                   False                    False   \n",
       "...                    ...                     ...                      ...   \n",
       "8581033              False                   False                    False   \n",
       "8581034              False                   False                    False   \n",
       "8581035              False                   False                    False   \n",
       "8581036              False                   False                    False   \n",
       "8581037              False                   False                    False   \n",
       "\n",
       "         vocab:#nårmusikkenstilner  vocab:#memyös  vocab:#timesup  \\\n",
       "0                            False          False           False   \n",
       "1                            False          False           False   \n",
       "2                            False          False           False   \n",
       "3                            False          False           False   \n",
       "4                            False          False           False   \n",
       "...                            ...            ...             ...   \n",
       "8581033                      False          False            True   \n",
       "8581034                      False          False            True   \n",
       "8581035                      False          False           False   \n",
       "8581036                      False          False           False   \n",
       "8581037                      False          False           False   \n",
       "\n",
       "         vocab:#niere  vocab:#jotambe  network_participation  \\\n",
       "0               False           False                      0   \n",
       "1               False           False                      0   \n",
       "2               False           False                      0   \n",
       "3               False           False                      0   \n",
       "4               False           False                      0   \n",
       "...               ...             ...                    ...   \n",
       "8581033         False           False                      1   \n",
       "8581034         False           False                      1   \n",
       "8581035         False           False                      1   \n",
       "8581036         False           False                      1   \n",
       "8581037         False           False                      1   \n",
       "\n",
       "         multiple_participation  \n",
       "0                         False  \n",
       "1                         False  \n",
       "2                         False  \n",
       "3                         False  \n",
       "4                         False  \n",
       "...                         ...  \n",
       "8581033                   False  \n",
       "8581034                   False  \n",
       "8581035                   False  \n",
       "8581036                   False  \n",
       "8581037                   False  \n",
       "\n",
       "[7939920 rows x 47 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simple counter of users either mentioned or replied to inside or outside the current author list\n",
    "\n",
    "users_actually_interacted_with = Counter()\n",
    "\n",
    "for row in df.itertuples():\n",
    "    try:\n",
    "        for mentioned in row.mentions:\n",
    "            users_actually_interacted_with[mentioned] += 1\n",
    "        users_actually_interacted_with[row.in_reply_to] += 1\n",
    "    except:\n",
    "        print(row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential sampling again from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 2010118),\n",
       " ('25073877', 125172),\n",
       " ('1917731', 95810),\n",
       " ('1367531', 91961),\n",
       " ('759251', 69922),\n",
       " ('14247236', 62094),\n",
       " ('32871086', 56299),\n",
       " ('49698134', 54523),\n",
       " ('2836421', 45869),\n",
       " ('807095', 31060)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_actually_interacted_with.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match on activity, let's collect their base timelines and see how much they tweeted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the output variables from this continuous time scope we need the peaks again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_conv(val):\n",
    "    return datetime.datetime.strptime('2017-10-16', '%Y-%m-%d') + datetime.timedelta(days=int(val))\n",
    "\n",
    "#obtain peak times again\n",
    "with h5py.File('/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/02_intermediate/FAS_peak_analysis.hdf5', 'r') as f:\n",
    "    FAS_peaks = f['peak_detections']\n",
    "\n",
    "    most_prominent_peaks = {}\n",
    "    for name, h5obj in FAS_peaks.items():\n",
    "        if len(h5obj['prominences']) == 0:\n",
    "            continue\n",
    "        max_prominence = np.argmax(h5obj['prominences'])\n",
    "        most_prominent_peaks[name] = unit_conv(h5obj['peak_locations'][max_prominence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 11, 30, 0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's just consider 私も and tôicũngvậy\n",
    "most_prominent_peaks['私も']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start creating the df needed for stats. Each user needs to have\n",
    "* normal activity before and after\n",
    "* hashtagged activity before and after\n",
    "* number of interactions with (each) protest network\n",
    "* protest networks participated in (organise by pairs?)\n",
    "* before and after peaks of each network participation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe start with splitting by hashtag\n",
    "# first split by multiple participation. These are the interactions we're most interested in\n",
    "\n",
    "multiple_ints_only = df[df['multiple_participation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do by user. first get list of all participating networks for each user\n",
    "\n",
    "# for author_id in df['author_id'].unique():\n",
    "\n",
    "df['author_total_hashtags'] = df['contains_hashtags'].apply(lambda x: [i for i in x if i.lower() in search_hashtags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peaks for each hashtag into the pandas\n",
    "for ht in search_hashtags:\n",
    "    if ht != 'وأناكمان':\n",
    "        with_sym_ht = f'#{ht}'\n",
    "        df[f'peak_{ht}'] = df['created_at'].apply(lambda x: x > most_prominent_peaks[ht].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'author_id', 'created_at', 'in_reply_to', 'mentions',\n",
       "       'quotes', 'replies', 'contains_hashtags', 'internal', 'vocab:#metoo',\n",
       "       'vocab:#balancetonporc', 'vocab:#moiaussi', 'vocab:#نه_یعنی_نه',\n",
       "       'vocab:#米兔', 'vocab:#我也是', 'vocab:#وأناكمان', 'vocab:#gamani',\n",
       "       'vocab:#tôicũngvậy', 'vocab:#私も', 'vocab:#watashimo', 'vocab:#나도',\n",
       "       'vocab:#나도당했다', 'vocab:#גםאנחנו', 'vocab:#ятоже', 'vocab:#ricebunny',\n",
       "       'vocab:#enazeda', 'vocab:#anakaman', 'vocab:#yotambien',\n",
       "       'vocab:#sendeanlat', 'vocab:#kutoo', 'vocab:#withyou', 'vocab:#wetoo',\n",
       "       'vocab:#cuentalo', 'vocab:#quellavoltache', 'vocab:#niunamenos',\n",
       "       'vocab:#woyeshi', 'vocab:#myharveyweinstein', 'vocab:#noustoutes',\n",
       "       'vocab:#stilleforopptak', 'vocab:#nårdansenstopper',\n",
       "       'vocab:#nårmusikkenstilner', 'vocab:#memyös', 'vocab:#timesup',\n",
       "       'vocab:#niere', 'vocab:#jotambe', 'network_participation',\n",
       "       'multiple_participation', 'author_total_hashtags', 'peak_metoo',\n",
       "       'peak_balancetonporc', 'peak_moiaussi', 'peak_نه_یعنی_نه', 'peak_米兔',\n",
       "       'peak_我也是', 'peak_gamani', 'peak_tôicũngvậy', 'peak_私も',\n",
       "       'peak_watashimo', 'peak_나도', 'peak_나도당했다', 'peak_גםאנחנו', 'peak_ятоже',\n",
       "       'peak_ricebunny', 'peak_enazeda', 'peak_anakaman', 'peak_yotambien',\n",
       "       'peak_sendeanlat', 'peak_kutoo', 'peak_withyou', 'peak_wetoo',\n",
       "       'peak_cuentalo', 'peak_quellavoltache', 'peak_niunamenos',\n",
       "       'peak_woyeshi', 'peak_myharveyweinstein', 'peak_noustoutes',\n",
       "       'peak_stilleforopptak', 'peak_nårdansenstopper',\n",
       "       'peak_nårmusikkenstilner', 'peak_memyös', 'peak_timesup', 'peak_niere',\n",
       "       'peak_jotambe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Input: Python Clustering Eval Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for vocabulary input. First load in the relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bsc model, features names, csr, and user ('document') ids\n",
    "\n",
    "bsc_model_list = glob.glob(os.path.join('/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/05_model_output/01_group','*.obj'))\n",
    "\n",
    "selected_model = 300\n",
    "\n",
    "selected_model = [i for i in bsc_model_list if int(re.split('[_.]',i)[-6])==selected_model][0]\n",
    "print(selected_model)\n",
    "\n",
    "with open(selected_model, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# open mapping also get relevent features names and user ids\n",
    "\n",
    "feature_mapping_file = '/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/02_intermediate/01_group/mapping_ngram_23.obj'\n",
    "with open(feature_mapping_file, 'rb') as f:\n",
    "    feature_names = pickle.load(f)\n",
    "\n",
    "# also load in csr\n",
    "csr_file = '/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/02_intermediate/01_group/user_count_mat_ngram_23.obj'\n",
    "with open(csr_file,'rb') as f:\n",
    "    csr = pickle.load(f)\n",
    "\n",
    "# get also the userlist that was used to generate this for 'document' names\n",
    "\n",
    "user_doc_ids = sorted(glob.glob(os.path.join('/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/01_raw','timeline*.jsonl')))\n",
    "user_doc_ids = [re.split('[_.]',i)[-2] for i in user_doc_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract top phrases from cluster\n",
    "def extract_cluster_words(feature_names, user_ids, csr, model, cluster_num):\n",
    "    row_ind, col_ind = model.get_indices(cluster_num)\n",
    "\n",
    "    csr_cluster = csr[row_ind][:,col_ind]\n",
    "    feature_csr_sums = csr_cluster.sum(axis=0)\n",
    "    top_features = np.argsort(feature_csr_sums)\n",
    "    top_features = np.asarray(top_features).flatten()\n",
    "    return [feature_names[i] for i in top_features[-1:-20:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_words_dict = {}\n",
    "\n",
    "for i in range(300):\n",
    "\n",
    "    cluster_words_dict[i] = extract_cluster_words(\n",
    "        feature_names,\n",
    "        user_doc_ids,\n",
    "        csr,\n",
    "        model,\n",
    "        i\n",
    "    )\n",
    "\n",
    "    if len(cluster_words_dict[i]) < 19:\n",
    "        cluster_words_dict[i] = cluster_words_dict[i] + [None]*(19-len(cluster_words_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_words = pd.DataFrame.from_dict(cluster_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a cluster of words\n",
    "selected_cluster = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, a statistical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before Vietnamese peak\n",
    "df[~df['peak_tôicũngvậy'] & df['vocab:#tôicũngvậy']]\n",
    "# after Vietnamese peak\n",
    "df[df['peak_tôicũngvậy'] & df['vocab:#tôicũngvậy']]\n",
    "# before Japanese peak:\n",
    "df[~df['peak_私も'] & df['vocab:#私も']]\n",
    "# after Japanese peak:\n",
    "df[df['peak_私も'] & df['vocab:#私も']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAS analysis file\n",
    "FAS_peak_analysis_file = '/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/02_intermediate/FAS_peak_analysis.hdf5'\n",
    "\n",
    "class daterange(NamedTuple):\n",
    "    start: str\n",
    "    end: str\n",
    "\n",
    "def daterange_from_group_num(group_num):\n",
    "    with h5py.File(FAS_peak_analysis_file, 'r') as f:\n",
    "        x = f['segments']['selected_ranges'][0]\n",
    "        res = daterange(\n",
    "            start = x[0].decode(),\n",
    "            end = x[1].decode()\n",
    "        )\n",
    "    return res\n",
    "\n",
    "# insert activity of users\n",
    "def date_to_array_index(date, daterange):\n",
    "    return (date - datetime.datetime.strptime(daterange.start, '%Y-%m-%d').date()).days\n",
    "\n",
    "def insert_activity_of_user(row, daterange=None, activity_file = None, activity='hashtagged', hashtag=None, group_num = 1, ht_row_mapping = None):\n",
    "\n",
    "    if activity == 'hashtagged':\n",
    "        if row[f'peak_{hashtag}']:\n",
    "            after = date_to_array_index(row['created_at'], daterange)\n",
    "            # get ht row index\n",
    "            assert hashtag in ht_row_mapping\n",
    "            ht_index = ht_row_mapping.index(hashtag)\n",
    "            result = activity[f'group_{group_num}'][row['author_id']][activity][ht_index,after:]\n",
    "        else:\n",
    "            after = date_to_array_index(row['created_at'], daterange)\n",
    "            # get ht row index\n",
    "            assert hashtag in ht_row_mapping\n",
    "            ht_index = ht_row_mapping.index(hashtag)\n",
    "            result = activity[f'group_{group_num}'][row['author_id']][activity][ht_index,after:]\n",
    "    else:\n",
    "        if row[f'peak_{hashtag}']:\n",
    "            after = date_to_array_index(row['created_at'], daterange)\n",
    "            # print(f'group_{group_num}', row['author_id'], after)\n",
    "            result = activity_file[f'group_{group_num}'][row['author_id']][activity][after:]\n",
    "        else:\n",
    "            up_to = date_to_array_index(row['created_at'], daterange)\n",
    "            # print(f'group_{group_num}', row['author_id'], up_to)\n",
    "            result = activity_file[f'group_{group_num}'][row['author_id']][activity][:up_to]\n",
    "\n",
    "    if result:\n",
    "        return np.sum(result)/len(result)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_file = '/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/03_processed/activity_counts.hdf5'\n",
    "\n",
    "with h5py.File(activity_file, 'r') as f:\n",
    "    # print(f.keys())\n",
    "    x = f['group_1']['1005675566']['hashtagged'].attrs['feature_order']\n",
    "    ht_row_mapping = x.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metoo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2005437/2470214746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mht\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'وأناكمان'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             df[f'activity_{hashtag}_normal'] = df.apply(\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0minsert_activity_of_user\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdaterange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_daterange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mseries_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseries_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_wrapped_if_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  10662\u001b[0m         \"\"\"\n\u001b[1;32m  10663\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10666\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, transpose, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1464\u001b[0m                     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0;31m# The underlying data was copied within _interleave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;31m# \"Union[ExtensionDtype, str, dtype[Any], Type[object], None]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;31m# \"Union[dtype[Any], ExtensionDtype, None]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_dtype_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dtype_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;31m# error: Incompatible return value type (got \"Union[ndarray, ExtensionArray]\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# expected \"ndarray\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "group_daterange = daterange_from_group_num(group_num)\n",
    "\n",
    "with h5py.File(activity_file, 'r') as f:\n",
    "    for ht in search_hashtags:\n",
    "        if ht != 'وأناكمان':\n",
    "            print(ht)\n",
    "            df[f'activity_{ht}_normal'] = df.apply(\n",
    "                insert_activity_of_user,\n",
    "                daterange = group_daterange,\n",
    "                activity_file = f,\n",
    "                hashtag = ht,\n",
    "                activity='normal',\n",
    "                axis=1\n",
    "            )\n",
    "# ht_row_mapping = activity[f'group_{group_num}'][row['author_id']]['feature_order']\n",
    "# ht_row_mapping = ht_row_mapping.split(':;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hubert/.local/lib/python3.9/site-packages/pandas/core/generic.py:2703: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['tweet_id', 'author_id', 'created_at', 'in_reply_to', 'mentions',\n",
      "       'quotes', 'replies', 'contains_hashtags', 'author_total_hashtags'],\n",
      "      dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "# save progress\n",
    "save_file = '/home/hubert/DPhil_Studies/2021-04_Study_A_Diffusion/data/06_reporting/combined_analysis.hdf5'\n",
    "\n",
    "df.to_hdf(save_file, 'group_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_a = 'metoo'\n",
    "ht_b = 'balancetonporc'\n",
    "filtered =  df[~df[f'peak_{ht}'] & df[f'vocab:#{ht_a}'] & df[f'vocab:#{ht_b}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "num_interacts = filtered.groupby(['author_id']).agg(int_pre_peak = pd.NamedAgg(column=\"tweet_id\", aggfunc=\"count\"))\n",
    "print(type(num_interacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(post peak activity)\n",
    "post_filtered = df[df[f'peak_{ht}'] & df[f'vocab:#{ht_a}'] & df[f'vocab:#{ht_b}']]\n",
    "post_filtered.sort_values('created_at', ascending=False).groupby(['author_id']).agg(post_peak_target = pd.NamedAgg(column=f\"activity_{ht_b}_normal\", aggfunc= lambda x: x.iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_pre_peak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1126372568</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134939868</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148746108</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491181038</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514035297</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161451768</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16447769</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691477732</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699266222</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169949875</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189869909</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930025695</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213074743</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217570564</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207688240</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387020435</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552546485</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720800274</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835136383</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970180045</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299233177</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201751805</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293087705</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3343572887</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469658161</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475704650</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566700592</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594100783</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631173995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813136916916957185</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817432950644101122</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823673648347303937</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827998533571706880</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831217002354184193</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862642923913007104</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907300601452793856</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93964759</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    act_pre_peak\n",
       "author_id                       \n",
       "1126372568                     2\n",
       "134939868                      2\n",
       "148746108                      2\n",
       "1491181038                     2\n",
       "1514035297                     3\n",
       "161451768                      2\n",
       "16447769                       2\n",
       "1691477732                     3\n",
       "1699266222                     2\n",
       "169949875                      2\n",
       "189869909                      2\n",
       "1930025695                     2\n",
       "213074743                      3\n",
       "217570564                      3\n",
       "2207688240                     2\n",
       "2387020435                     2\n",
       "2552546485                     2\n",
       "2720800274                     2\n",
       "2835136383                     2\n",
       "2970180045                     2\n",
       "299233177                      4\n",
       "3201751805                     3\n",
       "3293087705                     2\n",
       "3343572887                     2\n",
       "469658161                      2\n",
       "475704650                      2\n",
       "566700592                      2\n",
       "594100783                      2\n",
       "631173995                      2\n",
       "813136916916957185             2\n",
       "817432950644101122             3\n",
       "823673648347303937             2\n",
       "827998533571706880             2\n",
       "831217002354184193             3\n",
       "862642923913007104             2\n",
       "907300601452793856             2\n",
       "93964759                       2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.sort_values('created_at', ascending=False).groupby('author_id').agg(act_pre_peak = pd.NamedAgg(column=f'activity_{ht_b}_normal', aggfunc= lambda x: x.iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do by hashtag. group by users and then whether it was before peak\n",
    "class stats_df_tuple(NamedTuple):\n",
    "    ht_target: str\n",
    "    data: pd.DataFrame\n",
    "\n",
    "def retrieve_activity_user(row, daterange=None, activity_file = None, activity='hashtagged', hashtag=None, group_num = 1, ht_row_mapping = None):\n",
    "\n",
    "    if activity == 'hashtagged':\n",
    "        if row[f'peak_{hashtag}']:\n",
    "            after = date_to_array_index(row['created_at'], daterange)\n",
    "            # get ht row index\n",
    "            assert hashtag in ht_row_mapping\n",
    "            ht_index = ht_row_mapping.index(hashtag)\n",
    "            # print(f'group_{group_num}', row['author_id'], after)\n",
    "            result = activity_file[f'group_{group_num}'][row['author_id']][activity][ht_index,after:]\n",
    "        else:\n",
    "            up_to = date_to_array_index(row['created_at'], daterange)\n",
    "            # get ht row index\n",
    "            assert hashtag in ht_row_mapping\n",
    "            ht_index = ht_row_mapping.index(hashtag)\n",
    "            # print(f'group_{group_num}', row['author_id'], ht_index, up_to)\n",
    "            result = activity_file[f'group_{group_num}'][row['author_id']][activity][ht_index,:up_to]\n",
    "    else:\n",
    "        if row[f'peak_{hashtag}']:\n",
    "            after = date_to_array_index(row['created_at'], daterange)\n",
    "            # print(f'group_{group_num}', row['author_id'], after)\n",
    "            result = activity_file[f'group_{group_num}'][row['author_id']][activity][after:]\n",
    "        else:\n",
    "            up_to = date_to_array_index(row['created_at'], daterange)\n",
    "            # print(f'group_{group_num}', row['author_id'], up_to)\n",
    "            result = activity_file[f'group_{group_num}'][row['author_id']][activity][:up_to]\n",
    "\n",
    "    if len(result)>0:\n",
    "        s = np.sum(result)\n",
    "        # print(s)\n",
    "        return s\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "res = []\n",
    "with h5py.File(activity_file, 'r') as f:\n",
    "    for ht_target in search_hashtags[:1]:\n",
    "        # print(ht_target)\n",
    "        # take only the rows for before the peak. Group by \n",
    "        filtered =  df[~df[f'peak_{ht_target}'] & df[f'vocab:#{ht_target}']]\n",
    "        num_interacts = filtered.groupby(['author_id']).agg(int_pre_peak = pd.NamedAgg(column=\"tweet_id\", aggfunc=\"count\"))\n",
    "        act_pre_peak = filtered.sort_values('created_at', ascending=False).groupby('author_id').agg(lambda x: x.iloc[0]).reset_index()\n",
    "        if act_pre_peak.empty:\n",
    "            num_interacts['act_pre_peak'] = 0\n",
    "        else:\n",
    "            act_pre_peak['act_pre_peak'] = act_pre_peak.apply(\n",
    "                retrieve_activity_user,\n",
    "                daterange=group_daterange,\n",
    "                activity_file=f,\n",
    "                hashtag=ht_target,\n",
    "                group_num=1,\n",
    "                ht_row_mapping = ht_row_mapping,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            num_interacts = num_interacts.join(act_pre_peak[['author_id','act_pre_peak']].set_index('author_id'))\n",
    "\n",
    "        act_post_peak = df[df[f'peak_{ht_target}'] & df[f'vocab:#{ht_target}']]\n",
    "        act_post_peak = act_post_peak.sort_values('created_at', ascending=False).groupby('author_id').agg(lambda x: x.iloc[0]).reset_index()\n",
    "\n",
    "        if act_post_peak.empty:\n",
    "            num_interacts['act_post_peak'] = 0\n",
    "        else:\n",
    "            act_post_peak['act_post_peak'] = act_post_peak.apply(\n",
    "                retrieve_activity_user,\n",
    "                daterange=group_daterange,\n",
    "                activity_file=f,\n",
    "                hashtag=ht_target,\n",
    "                group_num=1,\n",
    "                ht_row_mapping = ht_row_mapping,\n",
    "                axis=1\n",
    "            )\n",
    "            temp = act_post_peak[['author_id','act_post_peak']].set_index('author_id')\n",
    "\n",
    "            num_interacts = num_interacts.join(temp)\n",
    "        num_interacts = num_interacts.reset_index().fillna(0)\n",
    "        num_interacts['ht'] = ht_target\n",
    "        res.append(stats_df_tuple(ht_target=ht_target, data=num_interacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "act_post_peak    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.concat([i.data for i in res], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>int_pre_peak</th>\n",
       "      <th>act_pre_peak</th>\n",
       "      <th>act_post_peak</th>\n",
       "      <th>ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10118982</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013557603</td>\n",
       "      <td>38</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023568159</td>\n",
       "      <td>33</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102496469</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1025741330</td>\n",
       "      <td>12</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>96825619</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>timesup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>97423151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timesup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>988406744</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timesup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>989210214</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>timesup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>99784623</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timesup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2993 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_id  int_pre_peak  act_pre_peak  act_post_peak       ht\n",
       "0      10118982             1           9.0            1.0    metoo\n",
       "1    1013557603            38          77.0            NaN    metoo\n",
       "2    1023568159            33          43.0            8.0    metoo\n",
       "3     102496469             2           0.0            NaN    metoo\n",
       "4    1025741330            12          23.0            1.0    metoo\n",
       "..          ...           ...           ...            ...      ...\n",
       "483    96825619             2           6.0            4.0  timesup\n",
       "484    97423151             1           0.0            NaN  timesup\n",
       "485   988406744             2           9.0            NaN  timesup\n",
       "486   989210214             2          17.0            2.0  timesup\n",
       "487    99784623             3          25.0            NaN  timesup\n",
       "\n",
       "[2993 rows x 5 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>int_pre_peak</th>\n",
       "      <th>act_pre_peak</th>\n",
       "      <th>act_post_peak</th>\n",
       "      <th>ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10118982</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013557603</td>\n",
       "      <td>38</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023568159</td>\n",
       "      <td>33</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102496469</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1025741330</td>\n",
       "      <td>12</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>98606948</td>\n",
       "      <td>8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>988406744</td>\n",
       "      <td>9</td>\n",
       "      <td>253.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>989210214</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>995054521</td>\n",
       "      <td>100</td>\n",
       "      <td>146.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>99784623</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>metoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2007 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id  int_pre_peak  act_pre_peak  act_post_peak     ht\n",
       "0       10118982             1           9.0            1.0  metoo\n",
       "1     1013557603            38          77.0            NaN  metoo\n",
       "2     1023568159            33          43.0            8.0  metoo\n",
       "3      102496469             2           0.0            NaN  metoo\n",
       "4     1025741330            12          23.0            1.0  metoo\n",
       "...          ...           ...           ...            ...    ...\n",
       "2002    98606948             8          76.0            1.0  metoo\n",
       "2003   988406744             9         253.0            3.0  metoo\n",
       "2004   989210214             2          17.0            NaN  metoo\n",
       "2005   995054521           100         146.0            NaN  metoo\n",
       "2006    99784623             1           0.0            1.0  metoo\n",
       "\n",
       "[2007 rows x 5 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_results = smf.ols('activity_私も_hashtagged ~ activity_私も_normal',\n",
    "    data=df[df['vocab:#私も']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching users on activity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
