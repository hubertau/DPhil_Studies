{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bertopic\n",
    "from loguru import logger\n",
    "import os\n",
    "import yt_dlp\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "import sys\n",
    "from pathlib import Path, PosixPath\n",
    "import requests\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class video_info:\n",
    "    id: str\n",
    "    username: str = field(default_factory=str, compare=False)\n",
    "    downloaded: bool = field(default_factory=bool, compare=False)\n",
    "    video_location: PosixPath = field(default_factory=PosixPath, compare=False)\n",
    "    comment_count: int = field(default_factory=int, compare=False)\n",
    "    digg_count: int = field(default_factory=int, compare=False)\n",
    "    play_count: int = field(default_factory=int, compare=False)\n",
    "    share_count: int = field(default_factory=int, compare=False)\n",
    "    whatsapp_share_count: int = field(default_factory=int, compare=False)\n",
    "    description: str = field(default_factory=str, compare=False)\n",
    "    ocr_text: str = field(default_factory=str, compare=False)\n",
    "    whisper_text: str = field(default_factory=str, compare=False)\n",
    "    concatenated: str = field(default_factory=str, compare=False)\n",
    "\n",
    "    def as_url(self, site='yt'):\n",
    "        if site == 'yt':\n",
    "            return f'https://www.youtube.com/watch?v={self.id}'\n",
    "        elif site == 'tiktok':\n",
    "            return f'https://www.tiktok.com/@{self.username}/video/{self.id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/YT/videolist_search7071_2023_12_12-14_24_28.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['position', 'channelId', 'channelTitle', 'videoId', 'publishedAt',\n",
       "       'publishedAtSQL', 'videoTitle', 'videoDescription', 'tags',\n",
       "       'videoCategoryId', 'videoCategoryLabel', 'topicCategories', 'duration',\n",
       "       'durationSec', 'dimension', 'definition', 'caption', 'defaultLanguage',\n",
       "       'defaultLAudioLanguage', 'thumbnail_maxres', 'licensedContent',\n",
       "       'locationDescription', 'latitude', 'longitude', 'viewCount',\n",
       "       'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(\n",
    "        file,\n",
    "        savepath,\n",
    "        overwrite = False,\n",
    "        max_download = None,\n",
    "        audio_only = True,\n",
    "        log_file = None,\n",
    "        show_tqdm = True\n",
    "    ):\n",
    "\n",
    "    if log_file:\n",
    "        logger.remove()\n",
    "        logger.add(log_file, backtrace=True, diagnose=True)\n",
    "    else:\n",
    "        logger.remove()\n",
    "        logger.add(sys.stderr, level=\"INFO\", backtrace=True, diagnose=True)\n",
    "\n",
    "    savefolder = 'audio' if audio_only else 'videos'\n",
    "\n",
    "    assert os.path.exists(savepath)\n",
    "    if not os.path.exists(savefolder):\n",
    "        os.makedirs(savefolder)\n",
    "\n",
    "    if max_download:\n",
    "        max_download = int(max_download)\n",
    "\n",
    "    all_ids = []\n",
    "    # with open(file, 'r') as f:\n",
    "    #     x = json.load(f)\n",
    "    #     for row in x['data']:\n",
    "    #         all_ids.append(video_info(\n",
    "    #             id = row['aweme_info']['aweme_id'],\n",
    "    #             username= row['aweme_info']['author']['unique_id']\n",
    "    #         ))\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    for row in df.itertuples(index=False):\n",
    "        all_ids.append(video_info(\n",
    "            id=row.videoId\n",
    "        ))\n",
    "\n",
    "    existing_videos = glob.glob(os.path.join(savepath, savefolder, '*.*'))\n",
    "    existing_videos = [Path(i).stem for i in existing_videos]\n",
    "    logger.debug(f'{existing_videos[:10]}')\n",
    "\n",
    "    ydl_opts= {\n",
    "        'outtmpl': os.path.join(savepath, f\"{savefolder}/%(id)s.%(ext)s\"),\n",
    "        'overwrites': overwrite,\n",
    "        'logger': logger,\n",
    "        'format': 'm4a/bestaudio/best',\n",
    "        # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
    "        'postprocessors': [{  # Extract audio using ffmpeg\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'm4a',\n",
    "        }],\n",
    "        # 'ffmpeg_location':'//opt//homebrew//bin//ffmpeg',\n",
    "    }\n",
    "    skipped = 0\n",
    "    success = 0\n",
    "    errored = 0\n",
    "\n",
    "    def tqdm_enumerate(iterable, use_tqdm=False):\n",
    "        if use_tqdm:\n",
    "            return enumerate(tqdm(iterable))\n",
    "        else:\n",
    "            return enumerate(iterable)\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        for counter, video in tqdm_enumerate(all_ids, use_tqdm=show_tqdm):\n",
    "            if video.id in existing_videos:\n",
    "                logger.info(f'{video.id} already downloaded. Continuing...')\n",
    "                skipped += 1\n",
    "                continue\n",
    "            logger.info(f\"processing {counter} of {len(all_ids)}, skipped {skipped}, errored: {errored}, max dl:{max_download}\")\n",
    "            if max_download is not None and counter-skipped >= max_download:\n",
    "                logger.info(f'Max download of {max_download} reached. Terminating...')\n",
    "                break\n",
    "            try:\n",
    "                ydl.download(video.as_url(site='yt'))\n",
    "                success += 1\n",
    "            except Exception:\n",
    "                logger.error('Something went wrong')\n",
    "                errored += 1\n",
    "    logger.info(f'Downloaded {success} succesfully, skipped {skipped} existing, {errored} failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565dcdbd3fad42f4a45ffed28115c2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download(\n",
    "    'Data/YT/videolist_search7071_2023_12_12-14_24_28.csv',\n",
    "    savepath='./Data/YT/',\n",
    "    # max_download=5,\n",
    "    log_file = './logs/YT_audio_download.log',\n",
    "    show_tqdm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dphil3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
